---
layout: blog
front: true
comments: True
flag: Server
background: gray
category: 后端
title: Redis 简介
date:  2019-07-08 21:38:00 GMT+0800 (CST)
update: 2019-08-16 12:49:00 GMT+0800 (CST)
background-image: /style/images/others/redis.jpg
tags:
- Server
---
# {{ page.title }}

**Redis(Remote Dictionary Service)** 即远程字典服务，是互联网技术领域使用最为广泛的存储中间件。Redis 以其超高的性能、完美的文档、简洁易懂的源码和丰富的客户端库支持在开源中间件领域广受好评。不同于之前文章就介绍的 Oracle 和 Mongodb，它是 key-value 型数据库，默认端口号为 6379。以下介绍基本[摘自掘进小册](https://juejin.im/book/5afc2e5f6fb9a07a9b362527/section/5afc2e5f51882542714ff291) 👍

> [网页在线体验戳这里](https://try.redis.io) 👈

## 基础类型

Redis 目前一共有五种基础类型:

| 基础类型        |   描述   |
| ------------ | ------- |
| 字符串 string | Redis 所有的数据结构都是以唯一的 key 字符串作为名称，然后通过这个唯一 key 值来获取相应的 value 数据 |
| 列表 list | 列表结构常用来做异步队列使用。将需要延后处理的任务结构体序列化成字符串塞进 Redis 的列表，另一个线程从这个列表中轮询数据进行处理 |
| 字典 hash | 内部实现结构上同 Java 的 HashMap 也是一致的，同样的数组 + 链表二维结构 |
| 集合 set | 相当于 Java 语言里面的 HashSet，它内部的键值对是无序的唯一的 |
| 有序集合 zset | 类似于 Java 的 SortedSet 和 HashMap 的结合体 |

### string / list / hash / set / zset

1、字符串 string

Redis 的字符串是**动态字符串**，是可以修改的字符串，内部结构实现上类似于 Java 的 ArrayList，采用预分配冗余空间的方式来减少内存的频繁分配，其最大长度为 512M。

```SHELL
# 键值对
> set name tate
OK
> get name
"tate"
> exists name
(integer) 1
> del name
(integer) 1
> get name
(nil)
```

```SHELL
# 批量键值对，节省网络耗时开销
> set name1 tate
OK
> set name2 holycoder
OK
> mget name1 name2 name3 # 返回一个列表
1) "tate"
2) "holycoder"
3) (nil)
> mset name1 boy name2 girl name3 unknown
> mget name1 name2 name3
1) "boy"
2) "girl"
3) "unknown"
```

还可以对 key 设置过期时间，到点自动删除，这个功能常用来控制缓存的失效时间:

```SHELL
> set name tate
> get name
"tate"
> expire name 5  # 5s 后过期
...  # wait for 5s
> get name
(nil)

> setex name 5 tate  # 5s 后过期，等价于 set+expire
> get name
"tate"
... # wait for 5s
> get name
(nil)

> setnx name tate  # 如果 name 不存在就执行 set 创建
(integer) 1
> get name
"tate"
> setnx name holycoder
(integer) 0  # 因为 name 已经存在，所以 set 创建不成功
> get name
"tate"  # 没有改变
```

2、列表 list

Redis 的列表相当于 Java 语言里面的 LinkedList，注意它是链表而不是数组。这意味着 list 的插入和删除操作非常快，时间复杂度为 O(1)，但是索引定位很慢，时间复杂度为 O(n):

![redis-list.gif]( {{site.url}}/style/images/smms/redis-list.gif )

```SHELL
# 栈: 右边进右边出
> rpush books python java golang
(integer) 3
> rpop books
"golang"
> rpop books
"java"
> rpop books
"python"
> rpop books
(nil)
```

3、字典 hash

Redis 的字典相当于 Java 语言里面的 HashMap，它是无序字典。内部实现结构上同 Java 的 HashMap 也是一致的，同样的数组 + 链表二维结构。第一维 hash 的数组位置碰撞时，就会将碰撞的元素使用链表串接起来。不同的是，Redis 的字典的值只能是字符串，另外它们 **rehash** 的方式不一样，因为 Java 的 HashMap 在字典很大时，rehash 是个耗时的操作，需要一次性全部 rehash。Redis 为了高性能，不能堵塞服务，所以采用了渐进式 rehash 策略:

![redis-hash.gif]( {{site.url}}/style/images/smms/redis-hash.gif )

hash 结构也可以用来存储用户信息，不同于字符串一次性需要全部序列化整个对象，hash 可以对用户结构中的每个字段单独存储。这样当我们需要获取用户信息时可以进行部分获取。而以整个字符串的形式去保存用户信息的话就只能一次性全部读取，这样就会比较浪费网络流量。但 hash 结构的存储消耗要高于单个字符串，到底该使用 hash 还是字符串，需要根据实际情况再三权衡:

```SHELL
> hset books java "think in java"  # 命令行的字符串如果包含空格，要用引号括起来
(integer) 1
> hset books golang "concurrency in go"
(integer) 1
> hset books python "python cookbook"
(integer) 1
> hgetall books  # entries()，key 和 value 间隔出现
1) "java"
2) "think in java"
3) "golang"
4) "concurrency in go"
5) "python"
6) "python cookbook"
> hlen books
(integer) 3
> hget books java
"think in java"
> hset books golang "learning go programming"  # 因为是更新操作，所以返回 0
(integer) 0
> hget books golang
"learning go programming"
> hmset books java "effective java" python "learning python" golang "modern golang programming"  # 批量 set
OK
```

4、集合 set

Redis 的集合相当于 Java 语言里面的 HashSet，它内部的键值对是无序的唯一的。它的内部实现相当于一个特殊的字典，字典中所有的 value 都是一个值 NULL:

![redis-set.gif]( {{site.url}}/style/images/smms/redis-set.gif )

set 结构可以用来存储活动中奖的用户 ID，因为有去重功能，可以保证同一个用户不会中奖两次:

```SHELL
> sadd books python
(integer) 1
> sadd books python  #  重复
(integer) 0
> sadd books java golang
(integer) 2
> smembers books  # 注意顺序，和插入的并不一致，因为 set 是无序的
1) "java"
2) "python"
3) "golang"
> sismember books java  # 查询某个 value 是否存在，相当于 contains(o)
(integer) 1
> sismember books rust
(integer) 0
> scard books  # 获取长度相当于 count()
(integer) 3
> spop books  # 弹出一个
"java"
```

5、有序集合 zset

zset 类似于 Java 的 SortedSet 和 HashMap 的结合体，一方面它是一个 set，保证了内部 value 的唯一性，另一方面它可以给每个 value 赋予一个 score，代表这个 value 的排序权重。它的内部实现用的是一种叫做[**跳跃列表**](https://juejin.im/book/5afc2e5f6fb9a07a9b362527/section/5b5ac63d5188256255299d9c)的数据结构:

![redis-zset.gif]( {{site.url}}/style/images/smms/redis-zset.gif )

例如 zset 可以用来存储学生的成绩，value 值是学生的 ID，score 是他的考试成绩。我们可以对成绩按分数进行排序就可以得到他的名次:

```SHELL
> zadd books 9.0 "think in java"
(integer) 1
> zadd books 8.9 "java concurrency"
(integer) 1
> zadd books 8.6 "java cookbook"
(integer) 1
> zrange books 0 -1  # 按 score 排序列出，参数区间为排名范围
1) "java cookbook"
2) "java concurrency"
3) "think in java"
> zrevrange books 0 -1  # 按 score 逆序列出，参数区间为排名范围
1) "think in java"
2) "java concurrency"
3) "java cookbook"
> zcard books  # 相当于 count()
(integer) 3
> zscore books "java concurrency"  # 获取指定 value 的 score
"8.9000000000000004"  # 内部 score 使用 double 类型进行存储，所以存在小数点精度问题
> zrank books "java concurrency"  # 排名
(integer) 1
> zrangebyscore books 0 8.91  # 根据分值区间遍历 zset
1) "java cookbook"
2) "java concurrency"
> zrangebyscore books -inf 8.91 withscores # 根据分值区间 (-∞, 8.91] 遍历 zset，同时返回分值。inf 代表 infinite，无穷大的意思。
1) "java cookbook"
2) "8.5999999999999996"
3) "java concurrency"
4) "8.9000000000000004"
> zrem books "java concurrency"  # 删除 value
(integer) 1
> zrange books 0 -1
1) "java cookbook"
2) "think in java"
```

以上这四种数据结构(除开字符串)是容器型数据结构，它们共享下面两条通用规则：

* **create if not exists**

如果容器不存在，那就创建一个，再进行操作。比如 rpush 操作刚开始是没有列表的，Redis 就会自动创建一个，然后再 rpush 进去新元素。

* **drop if no elements**

如果容器里元素没有了，那么立即删除元素，释放内存。这意味着 lpop 操作到最后一个元素，列表就消失了。

### 过期时间

Redis 所有的数据结构都可以设置过期时间，时间到了，Redis 会自动删除相应的对象。需要注意的是过期是以对象为单位，比如一个 hash 结构的过期是整个 hash 对象的过期，而不是其中的某个子 key。

还有一个需要特别注意的地方是如果一个字符串已经设置了过期时间，然后你调用了 set 方法修改了它，它的过期时间会消失:

```SHELL
> set tate yoyo
OK
> expire tate 600
(integer) 1
> ttl tate
(integer) 597
> set tate yoyo
OK
> ttl tate
(integer) -1
```

## 分布式锁

场景: 比如一个操作要修改用户的状态，修改状态需要先读出用户的状态，在内存里进行修改，改完了再存回去。如果这样的操作同时进行了，就会出现并发问题，因为读取和保存状态这两个操作不是**原子**的，即不会被线程调度机制打断的操作。这时候就会用到 Redis 的**分布式锁**。

分布式锁本质上要实现的目标就是在 Redis 里面占坑，一般是使用 **setnx**(set if not exists) 指令，只允许被一个客户端占坑。先来先占，用完了，再调用 del 指令释放茅坑。为了防止中间出现一些异常导出无法 del，一般会加个期限，过期后自动释放:

```SHELL
> setnx maokeng true
OK
> expire maokeng 5
... do something critical ...
> del maokeng
(integer) 1
```

但是如果在 setnx 和 expire 之间服务器进程突然挂掉了，无法调用 expire，则还是成了死锁。因此 Redis 2.8 版本中作者加入了 set 指令的扩展参数，使得 setnx 和 expire 指令可以一起执行:

```SHELL
# 原子指令
> set maokeng true ex 5 nx
OK
... do something critical ...
> del maokeng
```

伴随而来的还有一个问题，就是超时。如果在加锁和释放锁之间的逻辑执行的太长，以至于超出了锁的超时限制，就会出现问题。因为这时候第一个线程持有的锁过期了，临界区的逻辑还没有执行完，这个时候第二个线程就提前重新持有了这把锁，导致临界区代码不能得到严格的串行执行:

```PY
# 验证随机数是否一致
tag = random.nextint()  # 随机数
if redis.set(key, tag, nx=True, ex=5):
  do_something()
  redis.delifequals(key, tag)  # 假想的 delifequals 指令
```

匹配 value 和删除 key 不是一个原子操作，Redis 也没有提供类似于 delifequals 这样的指令。目前可以使用 [**Lua 脚本**](https://zh.wikipedia.org/wiki/Lua)来处理，因为 Lua 脚本可以保证连续多个指令的原子性执行，但也只是说相对更安全一些:

```SHELL
# delifequals
if redis.call("get",KEYS[1]) == ARGV[1] then
  return redis.call("del", KEYS[1])
else
  return 0
end
```

目前比较好的一个解决方案是 **RedLock**，简单来说，就是采用 N（通常是 5）个独立的 redis 节点，同时 setnx，如果多数节点成功，就拿到了锁，这样就可以允许少数（2）个节点挂掉了。

另外提到一下**可重入性**，指线程在持有锁的情况下再次请求加锁，如果一个锁支持同一个线程的多次加锁，那么这个锁就是可重入的，这里就不展开讨论了。

## 延时队列

首先我们了解下什么是[**消息队列(Message Queue)**](https://github.com/jasonGeng88/blog/blob/master/201705/MQ.md)，即 **MQ**。它是一种应用间的通信方式，消息发送后可以立即返回，由消息系统来确保消息的可靠传递。消息发布者只管把消息发布到 MQ 中而不用管谁来取，消息使用者只管从 MQ 中取消息而不管是谁发布的。这样发布者和使用者都不用知道对方的存在。市面上常用的有 [**RabbitMQ**](https://www.rabbitmq.com) 和 [**Kafka**](https://kafka.apache.org) 等，来给应用程序之间增加异步消息传递功能。

Redis 的消息队列不是专业的消息队列，使用起来比较简单，它没有非常多的高级特性，没有 ack 保证，如果对消息的可靠性有着极致的追求，那么它就不适合使用。Redis 的 list(列表) 数据结构常用来作为异步消息队列使用，使用 `rpush/lpush` 操作入队列，使用 `lpop/rpop` 来出队列。

客户端是通过队列的 pop 操作来获取消息，然后进行处理。处理完了再接着获取消息，再进行处理。如此循环往复，这便是作为队列消费者的客户端的生命周期。可是如果队列空了，客户端就会陷入 pop 的死循环，可能拉高客户端的 CPU 占用和 Redis 的 QPS，解决方案之一就是通过 sleep 指令让线程"睡一会儿":

```SHELL
time.sleep(1)  # python 睡 1s
Thread.sleep(1000)  # java 睡 1s
```

上述又会导致另一个问题，即消息的延迟增大，因此采用 `blpop/brpop` 替代前面的 `lpop/rpop`，就完美解决了上面的问题。这两个指令的前缀字符 b 代表的是 `blocking`，也就是**阻塞读**。阻塞读在队列没有数据的时候，会立即进入休眠状态，一旦数据到来，则立刻醒过来。消息的延迟几乎为零。

那么问题又来了，如果线程一直阻塞在哪里，Redis 的客户端连接就成了闲置连接，闲置过久，服务器一般会主动断开连接，减少闲置资源占用。这个时候 `blpop/brpop` 会抛出异常来，所以要注意捕获异常。

上面有一部分讲到了分布式锁的问题，但是没有提到客户端在处理请求时加锁没加成功怎么办。一般有 3 种策略来处理加锁失败：

* 直接抛出异常，通知用户稍后重试；
* sleep 一会再重试；
* 将请求转移至延时队列，过一会再试；

**延时队列**可以通过 Redis 的 zset(有序列表) 来实现。我们将消息序列化成一个字符串作为 zset 的 value，这个消息的到期处理时间作为score，然后用多个线程轮询 zset 获取到期的任务进行处理，多个线程是为了保障可用性，万一挂了一个线程还有其它线程可以继续处理。因为有多个线程，所以需要考虑并发争抢任务，确保任务不能被多次执行:

```PY
def delay(msg):
  msg.id = str(uuid.uuid4())  # 保证 value 值唯一
  value = json.dumps(msg)
  retry_ts = time.time() + 5  # 5 秒后重试
  redis.zadd("delay-queue", retry_ts, value)


def loop():
  while True:
    # 最多取 1 条
    values = redis.zrangebyscore("delay-queue", 0, time.time(), start=0, num=1)
    if not values:
      time.sleep(1)  # 延时队列空的，休息 1s
      continue
    value = values[0]  # 拿第一条，也只有一条
    success = redis.zrem("delay-queue", value)  # 从消息队列中移除该消息
    if success:  # 因为有多进程并发的可能，最终只会有一个进程可以抢到消息
      msg = json.loads(value)
      handle_msg(msg)
```

Redis 的 zrem 方法是多线程多进程争抢任务的关键，它的返回值决定了当前实例有没有抢到任务，因为 loop 方法可能会被多个线程、多个进程调用，同一个任务可能会被多个进程线程抢到，通过 zrem 来决定唯一的属主。同时，我们要注意一定要对 handle_msg 进行异常捕获，避免因为个别任务处理问题导致循环异常退出。

## HyperLogLog 统计

场景:如果要负责维护一个网站，要记录 PV 和 UV。PV 那非常好办，给每个网页一个独立的 Redis 计数器就可以了，这个计数器的 key 后缀加上当天的日期。这样来一个请求，incrby 一次，最终就可以统计出所有的 PV 数据。

UV 因为要考虑去重，一般想法是为每一个页面一个独立的 set 集合来存储所有当天访问过此页面的用户 ID。当一个请求过来时，我们使用 sadd 将用户 ID 塞进去就可以了。通过 scard 可以取出这个集合的大小，这个数字就是这个页面的 UV 数据。但是，如果你的页面访问量非常大，比如一个爆款页面几千万的 UV，你需要一个很大的 set 集合来统计，这就非常浪费空间。因此 **HyperLogLog** 就派上用场了。

Redis 提供了 HyperLogLog 数据结构就是用来解决这种统计问题的。HyperLogLog 提供不精确的去重计数方案，虽然不精确但是也不是非常不精确，标准误差是 0.81%。它提供了以下几个常用指令:

* **pfadd** - 增加计数
* **pfcount** - 获取计数
* **pfmerge** - 合并计数，用于将多个 pf 计数值累加在一起形成一个新的 pf 值

```SHELL
> pfadd tate user1
(integer) 1
> pfcount tate
(integer) 1
> pfadd tate user2 user3 user4 user5
(integer) 1
> pfcount tate
(integer) 5
```

> pfadd 中的 `pf` 是 HyperLogLog 数据结构发明人 Philippe Flajolet 的首字母缩写。

## 布隆过滤器

场景:我们在使用新闻客户端看新闻时，它会给我们不停地推荐新的内容，它每次推荐时要去重，去掉那些已经看过的内容。问题来了，新闻客户端推荐系统如何实现推送去重的?

如果历史记录存储在关系数据库里，去重就需要频繁地对数据库进行 exists 查询，当系统并发量很高时，数据库是很难扛住压力的。可能又想到了缓存，但是如此多的历史记录全部缓存起来，那得浪费多大存储空间呢？而且这个存储空间是随着时间线性增长。这时就需要用到**布隆过滤器(Bloom Filter)**了。它就是专门用来解决这种去重问题的。它在起到去重的同时，在空间上还能节省 90% 以上，只是稍微有那么点不精确，也就是有一定的误判概率。

布隆过滤器可以理解为一个不怎么精确的 set 结构，当你使用它的 `contains` 方法判断某个对象是否存在时，它可能会误判：当布隆过滤器说某个值存在时，这个值可能不存在；当它说不存在时，那就肯定不存在。Redis 官方提供的布隆过滤器到了 Redis 4.0 提供了插件功能之后才正式登场。布隆过滤器作为一个插件加载到 Redis Server 中，给 Redis 提供了强大的布隆去重功能，其基本命令如下:

* **bf.add** - 添加元素
* **bf.exists** - 查询元素是否存在
* **bf.madd** - 批量添加元素
* **bf.mexists** - 批量查询元素是否存在

```SHELL
> bf.add codehole user1
(integer) 1
> bf.add codehole user2
(integer) 1
> bf.add codehole user3
(integer) 1
> bf.exists codehole user1
(integer) 1
> bf.exists codehole user2
(integer) 1
> bf.exists codehole user3
(integer) 1
> bf.exists codehole user4
(integer) 0
> bf.madd codehole user4 user5 user6
1) (integer) 1
2) (integer) 1
3) (integer) 1
> bf.mexists codehole user4 user5 user6 user7
1) (integer) 1
2) (integer) 1
3) (integer) 1
4) (integer) 0
```

## 漏斗限流

场景:用户的发帖、回复、点赞等行为都要严格受控，一般要严格限定某行为在规定时间内允许的次数，超过了次数那就是非法行为。对非法行为，业务必须规定适当的惩处策略，因此除了控制流量，限流还有一个应用目的是用于控制用户行为，避免垃圾请求。

**漏斗限流(funnel)**是最常用的限流方法之一，顾名思义，这个算法的灵感源于漏斗(funnel)的结构。漏斗的剩余空间就代表着当前行为可以持续进行的数量，漏嘴的流水速率代表着系统允许该行为的最大频率。Redis 4.0 提供了一个限流 Redis 模块，它叫 **redis-cell**。该模块也使用了漏斗算法，并提供了原子的限流指令。该模块只有一条指令 `cl.throttle`:

```TEXT
> cl.throttle tate:reply 15 30 60 1
                   ▲     ▲  ▲  ▲  ▲
                   |     |  |  |  └───── need 1 quota (可选参数，默认值也是1)
                   |     |  └──┴─────── 30 operations / 60 seconds 这是漏水速率
                   |     └───────────── 15 capacity 这是漏斗容量
                   └─────────────────── key tate
```

## 高可用方案

### 主从复制

通过持久化功能，Redis 保证了即使在服务器重启的情况下也不会损失(或少量损失)数据，因为持久化会把内存中数据保存到硬盘上，重启会从硬盘上加载数据。但是由于数据是存储在一台服务器上的，如果这台服务器出现硬盘故障等问题，也会导致数据丢失。为了避免单点故障，通常的做法是将数据库复制多个副本以部署在不同的服务器上，这样即使有一台服务器出现故障，其他服务器依然可以继续提供服务。为此，Redis 提供了**复制(replication)**功能，可以实现当一台数据库中的数据更新后，自动将更新的数据同步到其他数据库上。

在复制的概念中，数据库分为两类，一类是**主数据库(master)**，另一类是**从数据库(slave)**。主数据库可以进行读写操作，当写操作导致数据变化时会自动将数据同步给从数据库。而从数据库一般是只读的，并接受主数据库同步过来的数据。一个主数据库可以拥有多个从数据库，而一个从数据库只能拥有一个主数据库。

### 哨兵模式 Sentinel

当主数据库遇到异常中断服务后，开发者可以通过手动的方式选择一个从数据库来升格为主数据库，以使得系统能够继续提供服务。然而整个过程相对麻烦且需要人工介入，难以实现自动化。为此，Redis 2.8 中提供了**哨兵**工具来实现自动化的系统监控和故障恢复功能。哨兵的作用就是监控 redis 主、从数据库是否正常运行，主出现故障自动将从数据库转换为主数据库。它的功能包括以下两个:

* 监控主数据库和从数据库是否正常运行
* 主数据库出现故障时自动将从数据库转换为主数据库

<!-- TODO: -->
<!-- ![image15.png]( {{site.url}}/style/images/smms/dom-node.jpg ) -->

默认情况下，每个 **Sentinel 节点**会以 每秒一次 的频率对 Redis 节点和其它的 Sentinel 节点发送 `PING` 命令，并通过节点的回复来判断节点是否在线:

* **主观下线** - 适用于所有主节点和从节点。如果在 `down-after-milliseconds` 毫秒内，Sentinel 没有收到目标节点的有效回复，则会判定该节点为主观下线
* **客观下线** - 只适用于主节点。如果主节点出现故障，Sentinel 节点会通过 `sentinel is-master-down-by-addr` 命令，向其它 Sentinel 节点询问对该节点的状态判断。如果超过 `<quorum>` 个数的节点判定主节点不可达，则该 Sentinel 节点会判断主节点为客观下线

主从切换的过程:

1. 在满足客观下线后，如果主节点处于 `SDOWN` 状态，则从 slave 中投票自动选出新的主节点
2. 其他 slave 修改为新 master 的 slave
3. 客户端修改连接
4. 老的 master 如果重启成功，变为新 master 的 slave

### 集群 cluster

即使使用哨兵，redis 每个实例也是全量存储，每个 redis 存储的内容都是完整的数据，浪费内存且有木桶效应。为了最大化利用内存，可以采用集群，就是分布式存储，即每台 redis 存储不同的内容，且为五中心结构，分布式方案一般有以下两种:

1、**客户端分区方案**

客户端就已经决定数据会被存储到哪个 redis 节点或者从哪个 redis 节点读取数据。其主要思想是采用哈希算法将 Redis 数据的 key 进行散列，通过 hash 函数，特定的 key 会映射到特定的 Redis 节点上，例如 **Redis Sharding**:

* 优点 - 不使用第三方中间件，分区逻辑可控，配置简单，节点之间无关联，容易线性扩展，灵活性强
* 缺点 - 客户端无法动态增删服务节点，客户端需要自行维护分发逻辑，客户端之间无连接共享，会造成连接浪费

![redis-cluster-client.png]( {{site.url}}/style/images/smms/redis-cluster-client.png )

2、**代理分区方案**

客户端发送请求到一个代理组件，代理解析客户端的数据，并将请求转发至正确的节点，最后将结果回复给客户端，例如 **Twemproxy** 和 **Codis**:

* 优点 - 简化客户端的分布式逻辑，客户端透明接入，切换成本低，代理的转发和存储分离
* 缺点 - 多了一层代理层，加重了架构部署复杂度和性能损耗

![redis-cluster-proxy.png]( {{site.url}}/style/images/smms/redis-cluster-proxy.png )

## 持久化

Redis 是内存数据库，数据都是存储在内存中，为了避免进程退出导致数据的永久丢失，需要定期将 Redis 中的数据从内存保存到硬盘。当下次 Redis 重启时，利用持久化文件实现数据恢复。除此之外，为了进行灾难备份，可以将持久化文件拷贝到一个远程位置。通常持久化提供了两种方式:

* **RDB** - 在指定的时间间隔能对数据进行快照存储
* **AOF** - 记录每次对服务器写的操作,当服务器重启的时候会重新执行这些命令来恢复原始的数据

### RDB

针对 RDB 方式的持久化，可以分为**手动触发**和**自动触发**。其中手动触发可以使用命令:

* **save** - 会阻塞当前 Redis 服务器，直到持久化完成，故线上不推荐使用
* **bgsave** - 该触发方式会 fork 一个子进程，由子进程负责持久化过程，因此阻塞只会发生在 fork 子进程的时候

```SHELL
$ save
OK
$ bgsave
Background saving started
fork operation complete
Background saving terminated with success
```

自动触发有以下几种情形，会触发 bgsave:

1. `save m n` 配置规则
2. 从节点全量复制时，主节点发送 rdb 文件给从节点完成复制操作，主节点会触发 bgsave
3. 执行 debug reload 时
4. 执行 shutdown 时，如果没有开启 aof，也会触发

上面提到 `save m n` 可以设置时间策略，当然还可以设置存储路径等信息:

```SHELL
# 表示 300s 内有 1 条写入，就产生快照
save 300 1
# 表示 600s 内有 10 条写入，就产生快照
save 600 10
# 禁用 RDB
save ""

# 文件名称
dbfilename dump.rdb

# 文件保存路径
dir /home/work/app/redis/data/

# 如果持久化出错，主进程是否停止写入
stop-writes-on-bgsave-error yes

# 是否压缩
rdbcompression yes

# 导入时是否检查
rdbchecksum yes
```

![redis-rdb.png]( {{site.url}}/style/images/smms/redis-rdb.png )

### AOF

AOF 则是将 Redis 执行的每次写命令记录到单独的日志文件中，当 Redis 重启时再次执行 AOF 文件中的命令来恢复数据。注意 Redis 服务器默认开启 RDB，关闭 AOF。若要开启 AOF，需要在配置文件中配置:

```SHELL
# 是否开启 aof
appendonly yes

# 文件名称
appendfilename "appendonly.aof"

# 同步方式，其他为 always 和 no
# 可能损失一秒的数据
appendfsync everysec

# aof重写期间是否同步
no-appendfsync-on-rewrite no

# 重写触发配置，防止 aof 文件过大，使用 bgrewriteaof 命令可以手动触发
auto-aof-rewrite-percentage 100
auto-aof-rewrite-min-size 64mb

# 加载aof时如果有错如何处理
aof-load-truncated yes

# 文件重写策略
aof-rewrite-incremental-fsync yes
```

其中 **appendfsync** 有以下三种策略:

| 策略 | 说明 | 优点 | 缺点 |
| ------------ | ------- | ------- | ------- |
| **always** | 每次有更新命令，便追加到 AOF 文件中 | 不丢失数据 | IO 开销大，影响 redis 性能 |
| **everysec** | 每秒写入一次 | 同时兼顾性能、数据 | 可能丢失 1 秒数据 |
| **no** | 将数据交给 OS 处理 | 不用管 | 不可控 |

![redis-aof.png]( {{site.url}}/style/images/smms/redis-aof.png )

> 恢复数据时，Redis 会优先加载 AOF，然后加载 RDB

### 持久化策略

一般来说，RDB 耗时时间长、和主进程抢占资源、有一定的数据丢失率、启动优先级较 AOF 低，数据恢复快。而 AOF 文件较 RDB 大很多，恢复慢，但是数据丢失少。

下面分场景来讨论持久化策略的选择，仅供参考，实际方案可能更复杂更具多样性:

* 如果 Redis 中的数据完全丢弃也没有关系(如 Redis 完全用作 DB 层数据的 cache)，那么无论是单机，还是主从架构，都可以不进行任何持久化
* 在单机环境下，如果可以接受十几分钟或更多的数据丢失，选择 RDB 对 Redis 的性能更加有利；如果只能接受秒级别的数据丢失，应该选择 AOF。
* 在主从环境下，slave 的存在既可以实现数据的热备，也可以进行读写分离分担 Redis 读请求，以及在 master 宕掉后继续提供服务。比如 master 可以完全关闭持久化来保证高性能，或者添加定时任务，在每天 Redis 空闲时调用 bgrewriteaof 手动触发 AOF

## 问题处理

### 缓存雪崩

一般是设置缓存时采用了相同的过期时间，导致同一时间内大批量 key 缓存过期失效，所有原本应该访问缓存的请求都去查询数据库了，而对数据库 CPU 和内存造成巨大压力，严重的会造成数据库宕机。从而形成一系列连锁反应，造成整个系统崩溃:

<!-- TODO: -->
<!-- ![image28.png]( {{site.url}}/style/images/smms/dom-node.jpg ) -->

解决方案:

1. 热点数据不设置过期时间，后台作业手动删除
1. 过期时间设置随机值
1. 限流、熔断

### 缓存击穿

高并发请求某个 key，它不存在或已过期，查询数据库，导致 DB 压力过大。

解决方案:

1. 热点数据提前预热(提前设置缓存)，并且不设置过期时间
2. 互斥锁(mutex key)

### 缓存穿透

某个 key 缓存、数据库均不存在。

解决方案:

1. 对查询请求做校验，比如 id < 0 直接返回
1. 写入默认值
1. 布隆过滤器 - 将所有可能存在的数据哈希到一个足够大的 bitmap 中，一个一定不存在的数据会被这个 bitmap 拦截掉，从而避免了对底层存储系统的查询压力

## tair

阿里云数据库 Redis 企业版（又称阿里云 Tair），是基于阿里集团内部使用的 Tair 产品研发的云上托管企业级内存数据库，从 2009 年开始正式承载阿里集团业务，历经天猫双十一、优酷春晚、菜鸟、高德等业务场景的磨练，是一款真正的企业级内存数据库产品。

> 详情可以看[这篇文章](https://help.aliyun.com/document_detail/145957.html) 👈

## 参考链接

1. [Redis 深度历险：核心原理与应用实践 - 掘进小册](https://juejin.im/book/5afc2e5f6fb9a07a9b362527/section/5afc2e5f51882542714ff291) By 老钱
2. [基于 Redis 的分布式锁到底安全吗？](http://zhangtielei.com/posts/blog-redlock-reasoning.html) By zhangtielei
3. [关于 redis 的主从、哨兵、集群](https://blog.csdn.net/c295477887/article/details/52487621) By 黄河边上的牧马人
4. [深入剖析 Redis 系列(二) - Redis 哨兵模式与高可用集群](https://juejin.im/post/5b7d226a6fb9a01a1e01ff64) By 零壹技术栈
5. [一文看懂 Redis 的持久化原理](https://juejin.im/post/5b70dfcf518825610f1f5c16) By 大愚Talk
6. [深入学习 Redis（2）：持久化](https://www.cnblogs.com/kismetv/p/8654978.html) By 编程迷思
